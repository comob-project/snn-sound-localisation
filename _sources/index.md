<!-- This is the home page of the jupyterbook website.
It is in the root directory so that it's URL is as simple as possible. -->

# About
<!-- This title is what appears in the TOC (left nav sidebar) -->

<br>

Welcome! This is an open and collaborative project where we model **sound localization** in the brain. How do neurons compute _where_ a sound is coming from, using just the signals in both ears? To investigate this, we train **spiking neural network** (SNN) models and analyze them.

We aim to work together on this and write a massive, joint paper. Everyone who contributes gets to be an author of that paper, regardless of whether or not their work is included in the final draft.

[Read on](Contributing.md) for how to join and contribute to this project.


## Context

This project is part of [COMOB](https://comob-project.github.io/), the project for collaborative modelling of the brain. It grew out of [Dan Goodman's tutorial][tut] for the 2022 Cosyne conference.

That tutorial gave a brief introduction to SNN models, and to the **surrogate gradient descent** method for training them. The tutorial's course materials are [freely available online][tut].

[tut]: https://neural-reckoning.github.io/cosyne-tutorial-2022/
