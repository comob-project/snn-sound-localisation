Inspired by the success of endeavours like the [Human Genome Project](https://www.genome.gov/human-genome-project) and [CERN](https://home.cern/), neuroscientists are increasingly initiating large-scale collaborations. The largest efforts, such as the [International Brain Laboratory](https://www.internationalbrainlab.com/) [@doi.org/10.1016/j.neuron.2017.12.013;@doi.org/10.1016/j.conb.2020.10.020], [The Blue Brain Project](https://www.epfl.ch/research/domains/bluebrain/) and [Human Brain Project](https://www.humanbrainproject.eu) bring together tens to hundreds of researchers across multiple laboratories. In terms of organisation, these projects follow a formal collaborative model with open outputs. That is, there are participating laboratories who collaborate together and then make their data, methods and results available. In this way, these projects have generated scientific insights, large-scale datasets, tools and educational materials. But, could there be advantages to these projects being organised differently and if so what are the alternatives {cite:p}`doi.org/10.1038/539159a`?

One alternative is bench marking contests, in which participants compete to obtain the best score on a specific task. Bench marking contests have driven progress in fields from computer vision {cite:p}`10.1109/CVPR.2009.5206848` to [protein folding](https://predictioncenter.org/), and have begun to enter neuroscience. For example, in [Brain-Score](https://www.brain-score.org/) [@10.1101/407007;@10.1016/j.neuron.2020.07.040] participants submit models, capable of completing a visual processing task, which are then ranked according to a quantitative metric. As participants can compete both remotely and independently, these contests offer a low barrier to entry. However, defining quantifiable endpoints for neuroscientific questions remains challenging {cite:p}`doi:10.1017/S0140525X22002813`.  

Another alternative is massively collaborative projects, in which a problem is openly stated and contributions are welcomed from anyone willing to participate. For example, in the [Polymath Project](https://polymathprojects.org/) unsolved mathematical problems are posed, and then participants share comments, ideas and equations online as they collectively work towards solutions. Similarly, the [Busy Beaver Challenge](https://bbchallenge.org/) recently [announced](https://discuss.bbchallenge.org/t/july-2nd-2024-we-have-proved-bb-5-47-176-870/237) a formal proof of a conjecture that was open for decades, [based mainly on online contributions from amateur mathematicians](https://www.quantamagazine.org/amateur-mathematicians-find-fifth-busy-beaver-turing-machine-20240702/).

Inspired by this approach, we founded [COMOB (Collaborative Modelling of the Brain)](https://comob-project.github.io/) - to explore if and how this collaborative model could be leveraged in neuroscience. This approach has two key differences from prior collaborative efforts in neuroscience. First, everything related to the project (code, results, writing) would be openly available from the outset. As such, we could benefit from continual feedback from the community. Second, anyone, anywhere in the world would be able to participate. Meaning, that individuals who may not normally have the opportunity to contribute to science, would be able to do so {cite:p}`doi.org/10.1038/539159a`. 

Here, we share our experiences and results. We start by detailing how we ran the project in terms of organisation and infrastructure in [](#metascience). We then briefly summarise our scientific results in [](#science). We conclude the main text with a [](#discussion) of what went well, what went wrong, and how future projects like this could learn from our experiences. Finally, in the [](#appendices) we provide detailed write-ups of our scientific results.