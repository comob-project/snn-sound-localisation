Inspired by the success of endeavours like the [Human Genome Project](https://www.genome.gov/human-genome-project) and [CERN](https://home.cern/), neuroscientists are increasingly initiating large-scale collaborations. The largest efforts, such as the [International Brain Laboratory](https://www.internationalbrainlab.com/) [@doi.org/10.1016/j.neuron.2017.12.013;@doi.org/10.1016/j.conb.2020.10.020], [The Blue Brain Project](https://www.epfl.ch/research/domains/bluebrain/) and [Human Brain Project](https://www.humanbrainproject.eu) bring together tens to hundreds of researchers across multiple laboratories. These projects have generated scientific insights, large-scale datasets, tools and educational materials. However, while they represent a step-change in scale, their workflow resembles many scientific endeavours. That is, there are participating laboratories who collaborate together and then make their data, methods and results available. As such, to participate, individuals must join a participating laboratory, initiate a collaboration with the project, or wait for the publication of data and resources. So how could these projects be structured differently{cite:p}`doi.org/10.1038/539159a`?

One alternative are bench marking contests, in which participants compete to obtain the best score on a specific task. Bench marking contests have driven progress in fields from computer vision {cite:p}`10.1109/CVPR.2009.5206848` to [protein folding](https://predictioncenter.org/), and have begun to enter neuroscience. For example, in [Brain-Score](https://www.brain-score.org/) [@10.1101/407007;@10.1016/j.neuron.2020.07.040] participants submit models, capable of completing a visual processing task, which are then ranked according to a quantitative metric. As participants can compete both remotely and independently, these contests offer a low barrier to entry. However, defining quantifiable endpoints for neuroscientific questions remains challenging {cite:p}`doi:10.1017/S0140525X22002813`.  

Another alternative are massively collaborative projects, in which a problem is openly stated and contributions are welcomed from anyone willing to participate. For example, in the [Polymath Project](https://polymathprojects.org/) unsolved mathematical problems are posed, and then participants share comments, ideas and equations online as they collectively work towards solutions. Similarly, the [Busy Beaver Challenge](https://bbchallenge.org/) recently [announced](https://discuss.bbchallenge.org/t/july-2nd-2024-we-have-proved-bb-5-47-176-870/237) a formal proof of a conjecture that was open for decades, [based mainly on online contributions from amateur mathematicians](https://www.quantamagazine.org/amateur-mathematicians-find-fifth-busy-beaver-turing-machine-20240702/). Inspired by this approach, we founded [COMOB (Collaborative Modelling of the Brain)](https://comob-project.github.io/) - to explore if and how this collaborative model could be leveraged in neuroscience. 

 Here, we share our experiences and results. We start by detailing how we ran the project in terms of organisation and infrastructure in [](#metascience). We then briefly summarise our scientific results in [](#science). We conclude the main text with a [](#discussion) of what went well, what went wrong, and how future projects like this could learn from our experiences. Finally, in the [](#appendices) we provide detailed write-ups of our scientific results.